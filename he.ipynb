{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "he.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "u55wkDkfrmEw"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/podschwadt/private_ai/blob/master/he.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3G_Tg5ONqOK"
      },
      "source": [
        "# Privacy Preserving Machine Learning\n",
        "\n",
        "First things first. Let's run the package installations. They take quite a while. So hit run on the cell below before continuing with this introduction.\n",
        "\n",
        "\n",
        "Executing? Perfect!  \n",
        "\n",
        "Consider the following scenario: You are business that speaclizes in machine learning. You have trained some great models on data that has been carefully collected and labeled. The data is quite sensitve and you had to jump through a lot of legal and hoops to get access to it. In this notebook this data will be represented by the android permission data that we have been working so far. Since that you are working on is sensitve and hard to get you are faced with a porblem. Your clients are reclutant to give you their data but at the same time you don't want to give your model to them either. \n",
        "But there are solutions to this problem and it this notebook we will explore to of those. Namely Secure Multiparty Computation SMC (also often called just Multi Party Computation  MPC) and Homomorphic Encryption(HE). Both are cryptographic ways of performing computation on data that is being kept secret. Here we will be focusing on HE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzxJKgI0ttbm"
      },
      "source": [
        "!pip install Pyfhel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K1fejzQOHlv"
      },
      "source": [
        "Next we'll get our usual boilerplat code out of the way. Data loading, splitting, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC4Gopq83IVf"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# select a subset of the data\n",
        "# we only wants ones and zeros\n",
        "# 200 instances per class\n",
        "\n",
        "# instances\n",
        "x_train = np.concatenate( [ x_train[ y_train == 0 ][ :200 ], x_train[ y_train == 1 ][ :200 ] ] )\n",
        "x_test = np.concatenate( [ x_test[ y_test == 0 ][ :200 ], x_test[ y_test == 1 ][ :200 ] ] )\n",
        "# x_train = x_train.astype( float ) / 255.\n",
        "# x_test = x_test.astype( float ) / 255.\n",
        "\n",
        "\n",
        "x_train_rounded = np.round( x_train )\n",
        "\n",
        "print( 'training data: ', x_train.shape )\n",
        "print( 'test data: ', x_test.shape )\n",
        "\n",
        "# labels\n",
        "y_train = np.concatenate( [ np.zeros( 200 ), np.ones( 200 ) ] )\n",
        "y_test = np.concatenate( [ np.zeros( 200 ), np.ones( 200 ) ] )\n",
        "\n",
        "print( 'training data: ', y_train.shape )\n",
        "print( 'test data: ', y_test.shape )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbZc1nu0YvnO"
      },
      "source": [
        "## Fully Homomorphic encryption\n",
        "\n",
        "Fully Homomorphic encryption is a tool that can be used for PPML. It does not rely on splitting the secret between parties to jointly evaluate a function. It is more like \"traditional\" cryptography in the sense that the one party encrypts the data. Any other party can perform computation the data without the need for decrypting it. The result of the computation is still encrypted. \n",
        "\n",
        "Opposed to whwat we have been doing so far we will not be working with a high level library but rather will build our own functions on top of simple operations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEqLf7XU0hwe"
      },
      "source": [
        "from Pyfhel import Pyfhel, PyPtxt, PyCtxt\n",
        "import time\n",
        "\n",
        "# Pyfhel class contains most of the functions.\n",
        "# PyPtxt is the plaintext class\n",
        "# PyCtxt is the ciphertext class\n",
        "\n",
        "\n",
        "HE = Pyfhel()           \n",
        "# p (long): Plaintext modulus. All operations are modulo p.\n",
        "# m (long=2048): Coefficient modulus.\n",
        "# flagBatching (bool=false): Set to true to enable batching.\n",
        "# base (long=2): Polynomial base.\n",
        "# sec (long=128): Security level equivalent in AES. 128 or 192.\n",
        "# intDigits (int=64): truncated positions for integer part.\n",
        "# fracDigits (int=32): truncated positions for fractional part.\n",
        "HE.contextGen(p=65537)  \n",
        "\n",
        "# generate keys\n",
        "HE.keyGen()           \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foLSTuXF6Jyt"
      },
      "source": [
        "Before we can encrypt nmumber we need to encode them. After that we can perform computation on the ciphertexts. Once we decrypt the result we need to decode it into the desired format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jp5FXlQ6Kcu"
      },
      "source": [
        "# plaintext values\n",
        "a = 1\n",
        "b = 2\n",
        "\n",
        "# encode\n",
        "a = HE.encodeInt( a )\n",
        "print('a:', a )\n",
        "b = HE.encodeInt( b )\n",
        "print('b:', b )\n",
        "\n",
        "# encrypt\n",
        "a_ctxt = HE.encrypt( a )\n",
        "b_ctxt = HE.encrypt( b )\n",
        "\n",
        "# perform computation\n",
        "result = a_ctxt + b_ctxt\n",
        "decrypted = HE.decrypt( result )\n",
        "\n",
        "# decrypt\n",
        "print( 'decrypted:', decrypted ) \n",
        "\n",
        "# decdode\n",
        "print( 'decoded:', HE.decodeInt( decrypted ) )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L26LQDtx-Xt-"
      },
      "source": [
        "Thankfully we don't have to encode and decode evertime. There are convience methods for it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRwzN-mL-XXI"
      },
      "source": [
        "# plaintext values\n",
        "a = 1\n",
        "b = 2\n",
        "\n",
        "# encpde and encrypt\n",
        "a_ctxt = HE.encryptInt( a )\n",
        "b_ctxt = HE.encryptInt( b )\n",
        "\n",
        "# perform computation\n",
        "result = a_ctxt + b_ctxt\n",
        "\n",
        "# decrypt and decdode\n",
        "print( 'decerypted and decoded:', HE.decryptInt( result ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjr4YTnB_fZC"
      },
      "source": [
        "Using the functions `encodeFrac`, `decodeFrac` and `encryptFrac` and `decryptFrac` to replicate the firs example with float values. What do you notice about the encoding?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNITITH8_1oE"
      },
      "source": [
        "# plaintext values\n",
        "a = .1\n",
        "b = .2\n",
        "\n",
        "# encode\n",
        "a = HE.encodeFrac( a )\n",
        "print('a:', a )\n",
        "b = HE.encodeFrac( b )\n",
        "print('b:', b)\n",
        "\n",
        "# encrypt\n",
        "a_ctxt = HE.encrypt( a )\n",
        "b_ctxt = HE.encrypt( b )\n",
        "\n",
        "# perform computation\n",
        "result = a_ctxt + b_ctxt\n",
        "decrypted = HE.decrypt( result )\n",
        "\n",
        "# decrypt\n",
        "print( 'decrypted:', decrypted ) \n",
        "print( 'decrypted polynomial:', decrypted.to_poly_string() ) \n",
        "\n",
        "# decdode\n",
        "print( 'decoded:', HE.decodeFrac( decrypted ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGM0vYOOKqz3"
      },
      "source": [
        "But what about the noise? I thought there was noise involved int HE?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1uN0CUAEPMo"
      },
      "source": [
        "HE = Pyfhel()           \n",
        "HE.contextGen( p=65537 )  \n",
        "# generate keys\n",
        "HE.keyGen()      \n",
        "\n",
        "\n",
        "# plaintext values\n",
        "a = 1\n",
        "b = 2\n",
        "\n",
        "# encpde and encrypt\n",
        "a_ctxt = HE.encryptInt( a )\n",
        "b_ctxt = HE.encryptInt( b )\n",
        "\n",
        "# perform computation\n",
        "result = a_ctxt * b_ctxt\n",
        "result = result * a_ctxt\n",
        "\n",
        "print( 'decerypted: ', HE.decrypt( result ) )\n",
        "print( 'decerypted and decoded:', HE.decryptInt( result ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQr2aRzxrOtu"
      },
      "source": [
        "# we can also estimate the noise budget\n",
        "HE.relinKeyGen(2,5)\n",
        "HE.multDepth()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiaGuxzFlkqs"
      },
      "source": [
        "We need to increase the noise budget"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBLMwgmXLMIJ"
      },
      "source": [
        "HE = Pyfhel()           \n",
        "# p (long): Plaintext modulus. All operations are modulo p.\n",
        "# m (long=2048): Coefficient modulus.\n",
        "# flagBatching (bool=false): Set to true to enable batching.\n",
        "# base (long=2): Polynomial base.\n",
        "# sec (long=128): Security level equivalent in AES. 128 or 192.\n",
        "# intDigits (int=64): truncated positions for integer part.\n",
        "# fracDigits (int=32): truncated positions for fractional part.\n",
        "HE.contextGen( p=65537, m=4096 )  \n",
        "\n",
        "# generate keys\n",
        "HE.keyGen()      \n",
        "\n",
        "# plaintext values\n",
        "a = 1\n",
        "b = 2\n",
        "\n",
        "# encpde and encrypt\n",
        "a_ctxt = HE.encryptInt( a )\n",
        "b_ctxt = HE.encryptInt( b )\n",
        "\n",
        "# perform computation\n",
        "result = a_ctxt * b_ctxt\n",
        "result = result * a_ctxt\n",
        "\n",
        "print( 'decerypted: ', HE.decrypt( result ) )\n",
        "print( 'decerypted and decoded:', HE.decryptInt( result ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ln5JzaqCki"
      },
      "source": [
        "# we can also estimate the noise budget\n",
        "HE.relinKeyGen(2,5)\n",
        "HE.multDepth()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1ztfvsB0iOI"
      },
      "source": [
        "For a simple example consider the following scenario. We are still working with the MNIST data set (that we all know and love) but to keep things simple we are only using two classes and small amount of data. First we are training a simple classifier on plain data. Namely a perceptron. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOmdQj2u2L7n"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "percp = Perceptron(fit_intercept=False)\n",
        "percp.fit( x_train.reshape( ( x_train.shape[ 0 ], -1 ) ), y_train )\n",
        "print( 'test score: ', percp.score( x_test.reshape( ( x_train.shape[ 0 ], -1 ) ), y_test ) )\n",
        "\n",
        "\n",
        "print( 'prediction:', percp.predict( x_test[ 1:2 ].reshape( ( 1, -1 ) ) ) )\n",
        "print( 'output:', percp.decision_function( x_test[ 1:2 ].reshape( ( 1, -1 ) ) ) )\n",
        "print( 'actual lable:', y_test[ 1:2 ] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWAJIsxcxhIh"
      },
      "source": [
        "Let's transfere the the perceptron algorithm to the encrypted domain. We can perform operations between plaintexts and ciphertexts but we need to encode the plaintexts first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kg6SNgiNPTw"
      },
      "source": [
        "from Pyfhel import Pyfhel, PyPtxt, PyCtxt\n",
        "import time\n",
        "\n",
        "# Pyfhel class contains most of the functions.\n",
        "# PyPtxt is the plaintext class\n",
        "# PyCtxt is the ciphertext class\n",
        "\n",
        "\n",
        "HE = Pyfhel()           \n",
        "# p (long): Plaintext modulus. All operations are modulo p.\n",
        "# m (long=2048): Coefficient modulus.\n",
        "# flagBatching (bool=false): Set to true to enable batching.\n",
        "# base (long=2): Polynomial base.\n",
        "# sec (long=128): Security level equivalent in AES. 128 or 192.\n",
        "# intDigits (int=64): truncated positions for integer part.\n",
        "# fracDigits (int=32): truncated positions for fractional part.\n",
        "HE.contextGen(p=65537)  \n",
        "\n",
        "# generate keys\n",
        "HE.keyGen()           \n",
        "\n",
        "# encrypt values\n",
        "inputs = [ HE.encryptInt( x ) for x in x_test[ 1 ].reshape( -1 ) ]\n",
        "prediction = HE.encryptInt( 0 )\n",
        "\n",
        "# encode weights\n",
        "weights = [ HE.encodeInt( x ) for x in percp.coef_[ 0 ] ]\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# perform prediction\n",
        "for w, x in zip( weights, inputs ):\n",
        "  temp = x * w\n",
        "  prediction = prediction + temp\n",
        "\n",
        "\n",
        "# decrypt results\n",
        "print( 'prediction took:', time.time() - start )\n",
        "result = HE.decryptInt( prediction )\n",
        "print( 'prediction:', result )\n",
        "print( 'actual label:', y_test[ 1 ] )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyC_UI8nrlfY"
      },
      "source": [
        "let's do it with SIMD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZACRcz2IURuo"
      },
      "source": [
        "HE = Pyfhel()           \n",
        "HE.contextGen( p=65537, flagBatching=True, )   \n",
        "\n",
        "# generate keys\n",
        "HE.keyGen()    \n",
        "\n",
        "# plain data\n",
        "a = [ 1,2,3,4 ]\n",
        "b = 2\n",
        "\n",
        "a = HE.encodeBatch( a )\n",
        "print( 'encoded:', a )\n",
        "\n",
        "a = HE.encrypt( a )\n",
        "\n",
        "# adding another value\n",
        "try:\n",
        "  print( 'try 1')\n",
        "  b_enc = HE.encodeInt( b )\n",
        "  a = a + b_enc\n",
        "  print( 'success!!')\n",
        "except Exception as e:\n",
        "  print( e )\n",
        "\n",
        "try:\n",
        "  print( 'try 2')\n",
        "  b_enc = HE.encodeBatch( b )\n",
        "  a = a + b_enc\n",
        "  print( 'success!!')\n",
        "except Exception as e:\n",
        "  print( e )\n",
        "\n",
        "try:\n",
        "  print( 'try 3')\n",
        "  b_enc = HE.encodeBatch( [b] * 4 )\n",
        "  a = a + b_enc\n",
        "  print( 'success!!')\n",
        "except Exception as e:\n",
        "  print( e )\n",
        "\n",
        "print( 'decoded and decrypted: ', HE.decryptBatch( a ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGgthRc7sLBx"
      },
      "source": [
        "HE = Pyfhel()           \n",
        "HE.contextGen( p=65537, flagBatching=True )  \n",
        "HE.keyGen()   \n",
        "# need to get data into the correct shape\n",
        "x_test = x_test.reshape( (x_test.shape[ 0 ], -1 ) )\n",
        "\n",
        "slots = HE.getnSlots()\n",
        "num_features = x_test.shape[ 1 ]\n",
        "\n",
        "print( x_test.shape )\n",
        "\n",
        "# encrypt values\n",
        "# iterate over every feature\n",
        "cipher_texts = []\n",
        "for i in range( num_features ):\n",
        "  feature = x_test[ :,i ] \n",
        "  cipher_texts.append( HE.encryptBatch( feature ) )\n",
        "\n",
        "prediction = HE.encryptBatch( [0] * num_features )\n",
        "\n",
        "# encode weights\n",
        "weights = [ HE.encodeBatch( [x] * num_features ) for x in percp.coef_[ 0 ] ]\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# perform prediction\n",
        "for w, x in zip( weights, cipher_texts ):\n",
        "  temp = x * w\n",
        "  prediction = prediction + temp\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# perform prediction\n",
        "\n",
        "# decrypt results\n",
        "print( 'prediction took:', time.time() - start )\n",
        "result = HE.decryptBatch( prediction )\n",
        "print( result )\n",
        "print( len(result) )\n",
        "\n",
        "\n",
        "print( percp.decision_function( x_test ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3Ek20_PMreG"
      },
      "source": [
        "Why did that not work?\n",
        "\n",
        "The outputs are too large. All operations are mod p.\n",
        "\n",
        "We neither a larger p or smaller outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2CKNn5pMsJ5"
      },
      "source": [
        "# change the weights to be smaller\n",
        "\n",
        "# create a copy of the preceptron\n",
        "percp1 = Perceptron(fit_intercept=False)\n",
        "percp1.classes_ = percp.classes_ \n",
        "coef = np.copy( percp.coef_ )\n",
        "\n",
        "# make changes to the coefficents\n",
        "coef = np.copy( percp.coef_ )\n",
        "coef[ coef > 0 ] = 1\n",
        "coef[ coef < 0 ] = -1\n",
        "\n",
        "percp1.coef_ = coef\n",
        "percp1.intercept_ = percp.intercept_\n",
        "\n",
        "print( 'test score: ', percp1.score( x_test.reshape( ( x_train.shape[ 0 ], -1 ) ), y_test ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOA-iWwWYWOT"
      },
      "source": [
        "HE = Pyfhel()           \n",
        "HE.contextGen( p=65537, flagBatching=True )  \n",
        "HE.keyGen()   \n",
        "# need to get data into the correct shape\n",
        "x_test = x_test.reshape( (x_test.shape[ 0 ], -1 ) )\n",
        "\n",
        "slots = HE.getnSlots()\n",
        "num_features = x_test.shape[ 1 ]\n",
        "\n",
        "print( x_test.shape )\n",
        "\n",
        "# encrypt values\n",
        "# iterate over every feature\n",
        "cipher_texts = []\n",
        "for i in range( num_features ):\n",
        "  feature = x_test[ :,i ] \n",
        "  cipher_texts.append( HE.encryptBatch( feature ) )\n",
        "\n",
        "prediction = HE.encryptBatch( [0] * num_features )\n",
        "\n",
        "# encode weights\n",
        "weights = [ HE.encodeBatch( [x] * num_features ) for x in percp1.coef_[ 0 ] ]\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# perform prediction\n",
        "for w, x in zip( weights, cipher_texts ):\n",
        "  temp = x * w\n",
        "  prediction = prediction + temp\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# perform prediction\n",
        "\n",
        "# decrypt results\n",
        "print( 'prediction took:', time.time() - start )\n",
        "result = HE.decryptBatch( prediction )\n",
        "print( result )\n",
        "print( len(result) )\n",
        "\n",
        "\n",
        "print( percp1.decision_function( x_test ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkuNVOUWLa9n"
      },
      "source": [
        "putting together the building blocks and building a simple neural network over\n",
        "encrypted data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgjJsD3BCHnw"
      },
      "source": [
        "# prepare the training data\n",
        "x_train = x_train.reshape( ( x_train.shape[ 0 ], -1 ) )\n",
        "x_test = x_test.reshape( ( x_test.shape[ 0 ], -1 ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZGxY-t5LekJ"
      },
      "source": [
        "# train a tiny neural network\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print( x_train.shape )\n",
        "\n",
        "model = Sequential()\n",
        "model.add( Dense( 2, activation='relu', input_shape=x_train.shape[ 1: ]  ) )\n",
        "model.add( Dense( 1, activation='sigmoid' ) )\n",
        "\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit( x_train, y_train, epochs=32, verbose=1 )\n",
        "model.evaluate( x_test, y_test )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_Ye34djOwUU"
      },
      "source": [
        "lets build a model that can work with HE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FpzUp4I4KLf"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# select a subset of the data\n",
        "# we only wants ones and zeros\n",
        "# 200 instances per class\n",
        "\n",
        "# instances\n",
        "x_train = np.concatenate( [ x_train[ y_train == 0 ][ :200 ], x_train[ y_train == 1 ][ :200 ] ] )\n",
        "x_test = np.concatenate( [ x_test[ y_test == 0 ][ :200 ], x_test[ y_test == 1 ][ :200 ] ] )\n",
        "# x_train = x_train.astype( float ) / 255.\n",
        "# x_test = x_test.astype( float ) / 255.\n",
        "\n",
        "\n",
        "x_train_rounded = np.round( x_train )\n",
        "\n",
        "print( 'training data: ', x_train.shape )\n",
        "print( 'test data: ', x_test.shape )\n",
        "\n",
        "# labels\n",
        "y_train = np.concatenate( [ np.zeros( 200 ), np.ones( 200 ) ] )\n",
        "y_test = np.concatenate( [ np.zeros( 200 ), np.ones( 200 ) ] )\n",
        "\n",
        "print( 'training data: ', y_train.shape )\n",
        "print( 'test data: ', y_test.shape )\n",
        "\n",
        "# prepare the training data\n",
        "x_train = x_train.reshape( ( x_train.shape[ 0 ], -1 ) )\n",
        "x_test = x_test.reshape( ( x_test.shape[ 0 ], -1 ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDN2Dx5FyLED"
      },
      "source": [
        "# fist we normalize the data\n",
        "x_train = x_train.astype( float ) / 255.\n",
        "x_test = x_test.astype( float ) / 255.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvMB9I4U3UoK"
      },
      "source": [
        "idx = np.arange(0,x_train.shape[1],4)\n",
        "x_train = x_train[:,idx]\n",
        "x_test = x_test[:,idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sj1waiq4Yw-"
      },
      "source": [
        "x_train[0]\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCDYnUM7yVof"
      },
      "source": [
        "def relu_aprox( x ):\n",
        "  return 0.046875*x**2 + 0.5*x + 0.9375\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add( Dense( 2 , activation=relu_aprox, input_shape=x_train.shape[ 1: ]  ) )\n",
        "model.add( Dense( 1 ) )\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit( x_train, y_train, epochs=32 )\n",
        "\n",
        "print( 'keras' )\n",
        "print( model.evaluate( x_test, y_test ) )\n",
        "print( 'prediction' )\n",
        "test_sample = x_test[ 0:1 ]\n",
        "print( 'prediction', model.predict( test_sample ) )\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhmf9IJ9yy88"
      },
      "source": [
        "Extract weights and setup the encryption scheme\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u55wkDkfrmEw"
      },
      "source": [
        "# HE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS_mB1ePDX7f"
      },
      "source": [
        "print( 'prediction', model.predict( test_sample ) )\n",
        "expected_result = model.predict( test_sample )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oja9JuBizQ7Y"
      },
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# setup HE\n",
        "#-------------------------------------------------------------------------------\n",
        "print('HE')\n",
        "HE = Pyfhel()           \n",
        "HE.contextGen(p=655370, m=2**13, fracDigits=128)  \n",
        "# generate keys\n",
        "HE.keyGen()    \n",
        "HE.relinKeyGen(16,5)\n",
        "print('multiplicative depth', HE.multDepth())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TChntqNrytDy"
      },
      "source": [
        "# extract weights\n",
        "print( 'weights layer 0' )\n",
        "layer0_weights = model.layers[ 0 ].get_weights() # format [ weights, biases ]\n",
        "print( layer0_weights[ 0 ].shape, layer0_weights[ 1 ].shape )\n",
        "\n",
        "print( 'weights layer 1' )\n",
        "layer1_weights = model.layers[ 1 ].get_weights()\n",
        "print( layer1_weights[ 0 ].shape, layer1_weights[ 1 ].shape )\n",
        "\n",
        "\n",
        "\n",
        "# let's implement the actual layers\n",
        "#-------------------------------------------------------------------------------\n",
        "# layers\n",
        "#-------------------------------------------------------------------------------\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efLrqhtf014Z"
      },
      "source": [
        "Convert values and encrypt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFDaCtA304O_"
      },
      "source": [
        "import sys\n",
        "#-------------------------------------------------------------------------------\n",
        "# convert values\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def weight_converter( weights, biases ):\n",
        "  bias_ = []     # holds converted biases \n",
        "  weights_ = []  # holds converted weights \n",
        "\n",
        "  # convert biases \n",
        "  print('converting biases')\n",
        "  for i, b in enumerate(biases):\n",
        "    sys.stdout.write(f'\\r  {i+1}/{len(biases)}')\n",
        "    bias_.append( HE.encodeFrac( b ) )\n",
        "  print()\n",
        "\n",
        "  # convert weights\n",
        "  print('converting weights')\n",
        "  i = 0\n",
        "  for input in weights:\n",
        "    w = []\n",
        "    for weight in input:\n",
        "      sys.stdout.write(f'\\r  {i+1}/{len(weights) * len(input)}')\n",
        "      w.append( HE.encodeFrac( weight ) )\n",
        "      i+=1\n",
        "    weights_.append( w )  \n",
        "  print()\n",
        "  return weights_, bias_\n",
        "\n",
        "# layer 0\n",
        "print(\"layer 0:\")\n",
        "weights_0, bias_0 = weight_converter( layer0_weights[ 0 ], layer0_weights[ 1 ] )\n",
        "# for i in range(len(layer0_weights[0])):\n",
        "#   print([HE.decodeFrac(x) for x in weights_0[i]], layer0_weights[0][i])\n",
        "# layer 1\n",
        "print(\"layer 1:\")\n",
        "weights_1, bias_1 = weight_converter( layer1_weights[ 0 ], layer1_weights[ 1 ] )\n",
        "\n",
        "\n",
        "# convert values for activation functions\n",
        "relu_aprox_coef = [ HE.encodeFrac( 0.046875 ),  HE.encodeFrac( 0.5 ), \n",
        "              HE.encodeFrac( 0.9375 ) ]\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# encrypt inputs\n",
        "#-------------------------------------------------------------------------------\n",
        "inputs = [ HE.encryptFrac( x ) for x in test_sample[ 0 ] ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjw9vG2i1F9z"
      },
      "source": [
        "Now it is your turn. Implement the layers. Good Luck :D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDTnZE091UvP"
      },
      "source": [
        "# ------------ layer 0 -----------------\n",
        "print('layer0:')\n",
        "units_0 = [ HE.encryptFrac( 0 ) for x in range( 2 ) ]\n",
        "\n",
        "# iterate over units\n",
        "count = 0\n",
        "for i in range( len( units_0 ) ):\n",
        "  # iterate over inpust\n",
        "  for j in range( len( inputs ) ):\n",
        "    sys.stdout.write(f'\\r  {count+1}/{len(units_0) * len(inputs)}')\n",
        "    prod = inputs[j] * weights_0[ j ][ i ]\n",
        "    HE.relinearize( prod )\n",
        "    units_0[ i ] = units_0[ i ] + prod\n",
        "    count += 1\n",
        "  units_0[ i ] = units_0[ i ] + bias_0[ i ]\n",
        "  \n",
        "  # f(units_0[ i ]) = a*units_0[ i ]^2 + b*units_0[ i ] + c \n",
        "  x_sqr = units_0[ i ] * units_0[ i ]\n",
        "  HE.relinearize( x_sqr )\n",
        "  a = x_sqr * relu_aprox_coef[ 0 ]\n",
        "  HE.relinearize( a )\n",
        "  b = units_0[ i ] * relu_aprox_coef[ 1 ] \n",
        "  HE.relinearize( b )\n",
        "  c = relu_aprox_coef[ 2 ] \n",
        "  units_0[ i ] = a + b + c\n",
        "\n",
        "print()\n",
        "\n",
        "\n",
        "# ------------ layer 1 -----------------\n",
        "print('layer1:')\n",
        "units_1 = [ HE.encryptFrac( 0 ) for x in range( 1 ) ]\n",
        "\n",
        "# iterate over units\n",
        "count = 0\n",
        "for i in range( len( units_1 ) ):\n",
        "  # iterate over inpust\n",
        "  for j in range( len( units_0 ) ):\n",
        "    sys.stdout.write(f'\\r  {count+1}/{len(units_1) * len(units_0)}')\n",
        "    prod = units_0[ j ] * weights_1[ j ][ i ]\n",
        "    HE.relinearize( prod )\n",
        "    units_1[ i ] = units_1[ i ] + prod\n",
        "    count += 1\n",
        "  units_1[ i ] = units_1[ i ] + bias_1[ i ]\n",
        "  \n",
        "\n",
        "# decrypt the result\n",
        "print( 'classification result' )\n",
        "print( HE.decryptFrac( units_1[ 0 ] )  )\n",
        "print('exptected result')\n",
        "print( model.predict( test_sample ) )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}